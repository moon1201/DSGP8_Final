{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beeb12c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:34:35.815170Z",
     "start_time": "2024-03-05T16:34:33.016062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: CausalBootstrapping in ./venv/lib/python3.11/site-packages (0.1.2)\r\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.11/site-packages (from CausalBootstrapping) (1.26.4)\r\n",
      "Requirement already satisfied: grapl-causal in ./venv/lib/python3.11/site-packages (from CausalBootstrapping) (1.6.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install CausalBootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66764a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:34:38.142302Z",
     "start_time": "2024-03-05T16:34:35.813639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in ./venv/lib/python3.11/site-packages (0.20.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca90858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:34:38.206896Z",
     "start_time": "2024-03-05T16:34:38.133861Z"
    }
   },
   "outputs": [],
   "source": [
    "import causalBootstrapping as cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77313c95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:34:39.572441Z",
     "start_time": "2024-03-05T16:34:38.199957Z"
    }
   },
   "outputs": [],
   "source": [
    "from distEst_lib import MultivarContiDistributionEstimator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "890ef903",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T16:34:39.574828Z",
     "start_time": "2024-03-05T16:34:39.562636Z"
    }
   },
   "outputs": [],
   "source": [
    "causal_graph = '\"Alcohol Consumption Causal Graph\"; \\\n",
    "                D; F; S; A; P; M; N; J; K; \\\n",
    "                F -> D; \\\n",
    "                S -> D; \\\n",
    "                A -> D; \\\n",
    "                P -> D; \\\n",
    "                M -> D; \\\n",
    "                N -> D; \\\n",
    "                J -> D; \\\n",
    "                K -> D; \\\n",
    "                S -> F; \\\n",
    "                A -> F; \\\n",
    "                P -> F; \\\n",
    "                M -> F; \\\n",
    "                N -> F; \\\n",
    "                J -> F; \\\n",
    "                K -> F; \\\n",
    "                M -> J; \\\n",
    "                N -> K; '\n",
    "# Dalc(D); Famrel(F); Sex(S); Age(A); Pstatus(P); Medu(M); Fedu(N); Mjob(J); Fjob(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2238b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T17:37:02.203127Z",
     "start_time": "2024-03-05T16:34:45.040775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interventional prob.:p_{S}(D)=\\sum_{A,K,M,N,J,P}[p(A,D,M,S,J,P|N,K)p(A,N,K,S,P|J,M)/p(S)p(A)p(S)p(P)]\n",
      "Causal bootstrapping weights function: [P(A,J,K,M,N,P,S)K(S,S')]/N*[P(S)P(A)P(K,N)P(S)P(P)P(J,M)]\n",
      "Required distributions:\n",
      "1: P(A,J,K,M,N,P,S)\n",
      "2: P(S)\n",
      "3: P(A)\n",
      "4: P(K,N)\n",
      "5: P(S)\n",
      "6: P(P)\n",
      "7: P(J,M)\n",
      "Kernel function required: K(S,S')\n"
     ]
    }
   ],
   "source": [
    "weight_func_lam, weight_func_str = cb.general_cb_analysis(causal_graph = causal_graph, \n",
    "                                                          effect_var_name = 'D', \n",
    "                                                          cause_var_name = 'S',\n",
    "                                                          info_print = True,\n",
    "                                                          idmode = \"shortest\",\n",
    "                                                          idgreedy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "60c2c562",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T23:32:19.901925Z",
     "start_time": "2024-03-05T23:32:19.813702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      sex  age  Pstatus  Medu  Fedu  famrel  Dalc  Walc  Mjob_at_home  \\\n0     0.0   18      0.0     4     4       4     1     1          True   \n1     0.0   17      1.0     1     1       5     1     1          True   \n2     0.0   15      1.0     1     1       4     2     3          True   \n3     0.0   15      1.0     4     2       3     1     1         False   \n4     0.0   16      1.0     3     3       4     1     2         False   \n...   ...  ...      ...   ...   ...     ...   ...   ...           ...   \n1039  0.0   19      1.0     2     3       5     1     2         False   \n1040  0.0   18      1.0     3     1       4     1     1         False   \n1041  0.0   18      1.0     1     1       1     1     1         False   \n1042  1.0   17      1.0     3     1       2     3     4         False   \n1043  1.0   18      1.0     3     2       4     3     4         False   \n\n      Mjob_health  Mjob_other  Mjob_services  Mjob_teacher  Fjob_at_home  \\\n0           False       False          False         False         False   \n1           False       False          False         False         False   \n2           False       False          False         False         False   \n3            True       False          False         False         False   \n4           False        True          False         False         False   \n...           ...         ...            ...           ...           ...   \n1039        False       False           True         False         False   \n1040        False       False          False          True         False   \n1041        False        True          False         False         False   \n1042        False       False           True         False         False   \n1043        False       False           True         False         False   \n\n      Fjob_health  Fjob_other  Fjob_services  Fjob_teacher  \n0           False       False          False          True  \n1           False        True          False         False  \n2           False        True          False         False  \n3           False       False           True         False  \n4           False        True          False         False  \n...           ...         ...            ...           ...  \n1039        False        True          False         False  \n1040        False       False           True         False  \n1041        False        True          False         False  \n1042        False       False           True         False  \n1043        False        True          False         False  \n\n[1044 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>age</th>\n      <th>Pstatus</th>\n      <th>Medu</th>\n      <th>Fedu</th>\n      <th>famrel</th>\n      <th>Dalc</th>\n      <th>Walc</th>\n      <th>Mjob_at_home</th>\n      <th>Mjob_health</th>\n      <th>Mjob_other</th>\n      <th>Mjob_services</th>\n      <th>Mjob_teacher</th>\n      <th>Fjob_at_home</th>\n      <th>Fjob_health</th>\n      <th>Fjob_other</th>\n      <th>Fjob_services</th>\n      <th>Fjob_teacher</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>18</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>17</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>15</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>15</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>16</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>0.0</td>\n      <td>19</td>\n      <td>1.0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1040</th>\n      <td>0.0</td>\n      <td>18</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1041</th>\n      <td>0.0</td>\n      <td>18</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1042</th>\n      <td>1.0</td>\n      <td>17</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1043</th>\n      <td>1.0</td>\n      <td>18</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>4</td>\n      <td>3</td>\n      <td>4</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1044 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "total_data = pd.read_csv(\"./student-encoded.csv\")\n",
    "total_data.drop(labels = ['goout', 'health'], axis=1)\n",
    "# Specify the desired features and target column\n",
    "desired_features = ['sex', 'age', 'Pstatus','Medu','Fedu','famrel' ,'Mjob', 'Fjob', 'Dalc','Walc']\n",
    "df = total_data[desired_features].copy()\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Mjob', 'Fjob'])\n",
    "\n",
    "# target_column = df['Walc']\n",
    "target_column = df['Dalc']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3468737e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T23:32:25.513546Z",
     "start_time": "2024-03-05T23:32:25.356180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: sex\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: age\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Pstatus\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Medu\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Fedu\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: famrel\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Dalc\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Walc\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Mjob_at_home\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Mjob_health\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Mjob_other\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Mjob_services\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Mjob_teacher\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Fjob_at_home\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Fjob_health\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Fjob_other\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Fjob_services\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n",
      "Feature: Fjob_teacher\n",
      "Training set size: 835\n",
      "Testing set size: 209\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Create a file to save the split data\n",
    "output_dir = \"./split_data/\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Iterate over each feature and split the dataset\n",
    "for column in df.columns:\n",
    "    # Get the data for the current feature\n",
    "    feature_data = df[[column]]\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_data, target_column, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Save the split training and testing sets as CSV files\n",
    "    train_filename = os.path.join(output_dir, f\"{column}_train.csv\")\n",
    "    test_filename = os.path.join(output_dir, f\"{column}_test.csv\")\n",
    "    X_train.to_csv(train_filename, index=False)\n",
    "    X_test.to_csv(test_filename, index=False)\n",
    "    \n",
    "    # Print the sizes of training and testing sets for each feature\n",
    "    print(f\"Feature: {column}\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Testing set size: {len(X_test)}\")\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "331aefa6",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-03-05T20:06:37.898113Z",
     "start_time": "2024-03-05T20:06:37.883025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      Mjob_at_home  Mjob_health  Mjob_other  Mjob_services  Mjob_teacher\n0             True        False       False          False         False\n1             True        False       False          False         False\n2             True        False       False          False         False\n3            False         True       False          False         False\n4            False        False        True          False         False\n...            ...          ...         ...            ...           ...\n1039         False        False       False           True         False\n1040         False        False       False          False          True\n1041         False        False        True          False         False\n1042         False        False       False           True         False\n1043         False        False       False           True         False\n\n[1044 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Mjob_at_home</th>\n      <th>Mjob_health</th>\n      <th>Mjob_other</th>\n      <th>Mjob_services</th>\n      <th>Mjob_teacher</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1039</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1040</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1041</th>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1042</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1043</th>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>1044 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = df\n",
    "total_data[['Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "19d8d123",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T23:32:29.362142Z",
     "start_time": "2024-03-05T23:32:29.277075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dalc(D); Famrel(F); Sex(S); Age(A); Pstatus(P); Medu(M); Fedu(N); Mjob(J); Fjob(K)\n",
    "# Read demo data\n",
    "testdata_dir = \"./split_data/\"\n",
    "D_train = pd.read_csv(testdata_dir + \"Dalc_train.csv\")\n",
    "# D_train = pd.read_csv(testdata_dir + \"Walc_train.csv\")\n",
    "F_train = pd.read_csv(testdata_dir + \"famrel_train.csv\")\n",
    "S_train = pd.read_csv(testdata_dir + \"sex_train.csv\")\n",
    "A_train = pd.read_csv(testdata_dir + \"age_train.csv\")\n",
    "P_train = pd.read_csv(testdata_dir + \"Pstatus_train.csv\")\n",
    "M_train = pd.read_csv(testdata_dir + \"Medu_train.csv\")\n",
    "N_train = pd.read_csv(testdata_dir + \"Fedu_train.csv\")\n",
    "\n",
    "Jathome_train = pd.read_csv(testdata_dir + \"Mjob_at_home_train.csv\")\n",
    "Jhealth_train = pd.read_csv(testdata_dir + \"Mjob_health_train.csv\")\n",
    "Jother_train = pd.read_csv(testdata_dir + \"Mjob_other_train.csv\")\n",
    "Jservices_train = pd.read_csv(testdata_dir + \"Mjob_services_train.csv\")\n",
    "Jteacher_train = pd.read_csv(testdata_dir + \"Mjob_teacher_train.csv\")\n",
    "Kathome_train = pd.read_csv(testdata_dir + \"Fjob_at_home_train.csv\")\n",
    "Khealth_train = pd.read_csv(testdata_dir + \"Fjob_health_train.csv\")\n",
    "Kother_train = pd.read_csv(testdata_dir + \"Fjob_other_train.csv\")\n",
    "Kservices_train = pd.read_csv(testdata_dir + \"Fjob_services_train.csv\")\n",
    "Kteacher_train = pd.read_csv(testdata_dir + \"Fjob_teacher_train.csv\")\n",
    "\n",
    "J_train = pd.concat([Jathome_train, Jhealth_train, Jother_train, Jservices_train, Jteacher_train], axis=1)\n",
    "K_train = pd.concat([Kathome_train, Khealth_train, Kother_train, Kservices_train, Kteacher_train], axis=1)\n",
    "\n",
    "# Reform the data to the acceptable format for the causalbootstrapping interfaces\n",
    "D_train = np.array(D_train)\n",
    "F_train = np.array(F_train)\n",
    "S_train = np.array(S_train)\n",
    "A_train = np.array(A_train)\n",
    "P_train = np.array(P_train)\n",
    "M_train = np.array(M_train)\n",
    "N_train = np.array(N_train)\n",
    "J_train = np.array(J_train)\n",
    "K_train = np.array(K_train)\n",
    "\n",
    "data = {\"D'\": D_train,\n",
    "        \"F\": F_train,\n",
    "        \"S\": S_train,\n",
    "        \"A\": A_train,\n",
    "        \"P\": P_train,\n",
    "        \"M\": M_train,\n",
    "        \"N\": N_train,\n",
    "        \"J\": J_train,\n",
    "        \"K\": K_train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f540d28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T23:32:37.331654Z",
     "start_time": "2024-03-05T23:32:37.304326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Interventional prob.:p_{S}(D)=\\sum_{N,P,K,A,J,M}[p(M,P,A,J,S,D|N,K)p(N,P,K,A,S|J,M)/p(S)p(P)p(S)p(A)]\n",
    "# Causal bootstrapping weights function: [P(A,J,K,M,N,P,S)K(S,S')]/N*[P(S)P(P)P(K,N)P(S)P(A)P(J,M)]\n",
    "# Required distributions:\n",
    "# 1: P(A,J,K,M,N,P,S)\n",
    "# 2: P(S)\n",
    "# 3: P(P)\n",
    "# 4: P(K,N)\n",
    "# 5: P(S)\n",
    "# 6: P(A)\n",
    "# 7: P(J,M)\n",
    "# Kernel function required: K(S,S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "71165b25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T23:33:51.532421Z",
     "start_time": "2024-03-05T23:32:37.327765Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set number of the bins for histogram becasue all variables follow discrete distributions.\n",
    "\n",
    "# Number of zeros depends on the dimension of the feature\n",
    "n_bins_ajkmnps = [3,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "n_bins_kn = [0,0,0,0,0,0]\n",
    "n_bins_jm = [0,0,0,0,0,0]\n",
    "n_bins_s = [0]\n",
    "n_bins_p = [0]\n",
    "n_bins_a = [0]\n",
    "\n",
    "data_ajkmnps = np.concatenate((A_train, J_train, K_train, M_train, N_train, P_train,S_train),axis=1)\n",
    "#data_ajkmnps = np.concatenate((A_train, J_train.reshape(-1,1), K_train.reshape(-1,1), M_train, N_train, P_train,S_train))\n",
    "data_kn = np.concatenate((K_train.reshape(-1,1), N_train))\n",
    "data_jm = np.concatenate((J_train.reshape(-1,1), M_train))\n",
    "data_s = S_train\n",
    "data_p = P_train\n",
    "data_a = A_train\n",
    "\n",
    "# TODO: Change it to the new distribution\n",
    "dist_estimator_ajkmnps = MultivarContiDistributionEstimator(data_fit=data_ajkmnps, n_bins = n_bins_ajkmnps)\n",
    "pdf_ajkmnps, pajkmnps = dist_estimator_ajkmnps.fit_histogram()\n",
    "dist_estimator_kn = MultivarContiDistributionEstimator(data_fit=data_kn, n_bins = n_bins_kn)\n",
    "pdf_kn, pkn = dist_estimator_kn.fit_histogram()\n",
    "dist_estimator_jm = MultivarContiDistributionEstimator(data_fit=data_jm, n_bins = n_bins_jm)\n",
    "pdf_jm, pjm = dist_estimator_jm.fit_histogram()\n",
    "dist_estimator_s = MultivarContiDistributionEstimator(data_fit=data_s, n_bins = n_bins_s)\n",
    "pdf_s, ps = dist_estimator_s.fit_histogram()\n",
    "dist_estimator_p = MultivarContiDistributionEstimator(data_fit=data_p, n_bins = n_bins_p)\n",
    "pdf_p, pp = dist_estimator_p.fit_histogram()\n",
    "dist_estimator_a = MultivarContiDistributionEstimator(data_fit=data_a, n_bins = n_bins_a)\n",
    "pdf_a, pa = dist_estimator_a.fit_histogram()\n",
    "\n",
    "dist_map = {tuple(sorted([\"A\", \"J\", \"K\", \"M\", \"N\", \"P\", \"S\"])): lambda A, J, K, M, N, P, S: pdf_ajkmnps([A, J, K, M, N, P, S]) ,\n",
    "            tuple(sorted([\"K\",\"N\"])): lambda K, N: pdf_kn([K, N]),\n",
    "            tuple(sorted([\"J\",\"M\"])): lambda J, M: pdf_jm([J, M]),\n",
    "            tuple(sorted([\"S\"])): lambda S: pdf_s([S]),\n",
    "            tuple(sorted([\"P\"])): lambda P: pdf_p([P]),\n",
    "            tuple(sorted([\"A\"])): lambda A: pdf_a([A])}\n",
    "\n",
    "SS = eval(\"lambda \"+ \"D\" +\",\"+ \"S\" +\": 1 if \"+ \"D\" +\"==\" + \"S\" + \" else 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e0b8585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T23:33:52.629963Z",
     "start_time": "2024-03-05T23:33:51.536571Z"
    }
   },
   "outputs": [],
   "source": [
    "cb_data = cb.general_causal_bootstrapping_simple(weight_func_lam = weight_func_lam, \n",
    "                                                 dist_map = dist_map, data = data, \n",
    "                                                 intv_var_name = \"S\", kernel = SS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22593069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T23:33:52.903626Z",
     "start_time": "2024-03-05T23:33:52.638239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      1.00      0.76       127\n",
      "         1.0       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.61       209\n",
      "   macro avg       0.30      0.50      0.38       209\n",
      "weighted avg       0.37      0.61      0.46       209\n",
      "\n",
      "0.6076555023923444 0.6076555023923444 0.459358623832308\n",
      "Report of de-confonded model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.84      0.76       127\n",
      "         1.0       0.63      0.41      0.50        82\n",
      "\n",
      "    accuracy                           0.67       209\n",
      "   macro avg       0.66      0.63      0.63       209\n",
      "weighted avg       0.67      0.67      0.66       209\n",
      "\n",
      "0.6746411483253588 0.6746411483253588 0.6573008924632665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monica/Desktop/DSGP8/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/monica/Desktop/DSGP8/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/monica/Desktop/DSGP8/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "# clf_conf = svm.SVC(kernel = 'linear', C=2)\n",
    "clf_conf = XGBClassifier()\n",
    "clf_conf.fit(D_train, S_train)\n",
    "\n",
    "# clf_cb = svm.SVC(kernel = 'linear', C=2)\n",
    "clf_cb = XGBClassifier()\n",
    "clf_cb.fit(cb_data['D'], cb_data[\"intv_S\"])\n",
    "\n",
    "D_test = pd.read_csv(testdata_dir +  \"Dalc_test.csv\")\n",
    "# D_test = pd.read_csv(testdata_dir + \"Walc_test.csv\")\n",
    "S_test = pd.read_csv(testdata_dir +  \"sex_test.csv\")\n",
    "D_test = np.array(D_test)\n",
    "S_test = np.array(S_test)\n",
    "\n",
    "S_pred_conf = clf_conf.predict(S_test)\n",
    "print(\"Report of confonded model:\")\n",
    "print(classification_report(S_test, S_pred_conf))\n",
    "print(accuracy_score(S_test, S_pred_conf), recall_score(S_test, S_pred_conf, average=\"weighted\"), f1_score(S_test, S_pred_conf, average='weighted'))\n",
    "\n",
    "S_pred_deconf = clf_cb.predict(D_test)\n",
    "print(\"Report of de-confonded model:\")\n",
    "print(classification_report(S_test, S_pred_deconf))\n",
    "print(accuracy_score(S_test, S_pred_deconf), recall_score(S_test, S_pred_deconf, average='weighted'), f1_score(S_test, S_pred_deconf, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69cd47ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T14:27:41.751655Z",
     "start_time": "2024-03-05T14:27:41.540100Z"
    }
   },
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "The data appears to lie in a lower-dimensional subspace of the space in which it is expressed. This has resulted in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Consider performing principle component analysis / dimensionality reduction and using `gaussian_kde` with the transformed data.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mLinAlgError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/scipy/stats/_kde.py:226\u001B[0m, in \u001B[0;36mgaussian_kde.__init__\u001B[0;34m(self, dataset, bw_method, weights)\u001B[0m\n\u001B[1;32m    225\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 226\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_bandwidth\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbw_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbw_method\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m linalg\u001B[38;5;241m.\u001B[39mLinAlgError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/scipy/stats/_kde.py:574\u001B[0m, in \u001B[0;36mgaussian_kde.set_bandwidth\u001B[0;34m(self, bw_method)\u001B[0m\n\u001B[1;32m    572\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m--> 574\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_covariance\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/scipy/stats/_kde.py:586\u001B[0m, in \u001B[0;36mgaussian_kde._compute_covariance\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_covariance \u001B[38;5;241m=\u001B[39m atleast_2d(cov(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, rowvar\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m    584\u001B[0m                                        bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    585\u001B[0m                                        aweights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweights))\n\u001B[0;32m--> 586\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_cho_cov \u001B[38;5;241m=\u001B[39m \u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcholesky\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_covariance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    587\u001B[0m \u001B[43m                                         \u001B[49m\u001B[43mlower\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcovariance \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_covariance \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfactor\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py:88\u001B[0m, in \u001B[0;36mcholesky\u001B[0;34m(a, lower, overwrite_a, check_finite)\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;124;03mCompute the Cholesky decomposition of a matrix.\u001B[39;00m\n\u001B[1;32m     47\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     86\u001B[0m \n\u001B[1;32m     87\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m---> 88\u001B[0m c, lower \u001B[38;5;241m=\u001B[39m \u001B[43m_cholesky\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlower\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverwrite_a\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverwrite_a\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mcheck_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcheck_finite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m c\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/scipy/linalg/_decomp_cholesky.py:36\u001B[0m, in \u001B[0;36m_cholesky\u001B[0;34m(a, lower, overwrite_a, clean, check_finite)\u001B[0m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 36\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m LinAlgError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-th leading minor of the array is not positive \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     37\u001B[0m                       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefinite\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m info)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mLinAlgError\u001B[0m: 6-th leading minor of the array is not positive definite",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mLinAlgError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Use kde to estimate\u001B[39;00m\n\u001B[1;32m      2\u001B[0m dist_estimator_ajkmnps \u001B[38;5;241m=\u001B[39m MultivarContiDistributionEstimator(data_fit\u001B[38;5;241m=\u001B[39mdata_ajkmnps, n_bins \u001B[38;5;241m=\u001B[39m n_bins_ajkmnps)\n\u001B[0;32m----> 3\u001B[0m pdf_ajkmnps, pajkmnps \u001B[38;5;241m=\u001B[39m \u001B[43mdist_estimator_ajkmnps\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_kde\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m dist_estimator_kn \u001B[38;5;241m=\u001B[39m MultivarContiDistributionEstimator(data_fit\u001B[38;5;241m=\u001B[39mdata_kn, n_bins \u001B[38;5;241m=\u001B[39m n_bins_kn)\n\u001B[1;32m      5\u001B[0m pdf_kn, pkn \u001B[38;5;241m=\u001B[39m dist_estimator_kn\u001B[38;5;241m.\u001B[39mfit_kde()\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/distEst_lib.py:88\u001B[0m, in \u001B[0;36mMultivarContiDistributionEstimator.fit_kde\u001B[0;34m(self, bandwidth, data_est)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_kde\u001B[39m(\u001B[38;5;28mself\u001B[39m, bandwidth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, data_est \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m---> 88\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mest_dist \u001B[38;5;241m=\u001B[39m \u001B[43mgaussian_kde\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_fit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbw_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbandwidth\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     89\u001B[0m     pos \u001B[38;5;241m=\u001B[39m ndgrid_gen(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_est, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_bins, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mflatten\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     90\u001B[0m     est_pdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mest_dist(pos)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_bins)\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/scipy/stats/_kde.py:235\u001B[0m, in \u001B[0;36mgaussian_kde.__init__\u001B[0;34m(self, dataset, bw_method, weights)\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m linalg\u001B[38;5;241m.\u001B[39mLinAlgError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    228\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe data appears to lie in a lower-dimensional subspace \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    229\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof the space in which it is expressed. This has resulted \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    230\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min a singular data covariance matrix, which cannot be \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    233\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manalysis / dimensionality reduction and using \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    234\u001B[0m            \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`gaussian_kde` with the transformed data.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 235\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m linalg\u001B[38;5;241m.\u001B[39mLinAlgError(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mLinAlgError\u001B[0m: The data appears to lie in a lower-dimensional subspace of the space in which it is expressed. This has resulted in a singular data covariance matrix, which cannot be treated using the algorithms implemented in `gaussian_kde`. Consider performing principle component analysis / dimensionality reduction and using `gaussian_kde` with the transformed data."
     ]
    }
   ],
   "source": [
    "# Use kde to estimate\n",
    "dist_estimator_ajkmnps = MultivarContiDistributionEstimator(data_fit=data_ajkmnps, n_bins = n_bins_ajkmnps)\n",
    "pdf_ajkmnps, pajkmnps = dist_estimator_ajkmnps.fit_kde()\n",
    "dist_estimator_kn = MultivarContiDistributionEstimator(data_fit=data_kn, n_bins = n_bins_kn)\n",
    "pdf_kn, pkn = dist_estimator_kn.fit_kde()\n",
    "dist_estimator_jm = MultivarContiDistributionEstimator(data_fit=data_jm, n_bins = n_bins_jm)\n",
    "pdf_jm, pjm = dist_estimator_jm.fit_kde()\n",
    "dist_estimator_s = MultivarContiDistributionEstimator(data_fit=data_s, n_bins = n_bins_s)\n",
    "pdf_s, ps = dist_estimator_s.fit_kde()\n",
    "dist_estimator_p = MultivarContiDistributionEstimator(data_fit=data_p, n_bins = n_bins_p)\n",
    "pdf_p, pp = dist_estimator_p.fit_kde()\n",
    "dist_estimator_a = MultivarContiDistributionEstimator(data_fit=data_a, n_bins = n_bins_a)\n",
    "pdf_a, pa = dist_estimator_a.fit_kde()\n",
    "\n",
    "dist_map = {tuple(sorted([\"A\", \"J\", \"K\", \"M\", \"N\", \"P\", \"S\"])): lambda A, J, K, M, N, P, S: pdf_ajkmnps([A, J, K, M, N, P, S]) ,\n",
    "            tuple(sorted([\"K\",\"N\"])): lambda K, N: pdf_kn([K, N]),\n",
    "            tuple(sorted([\"J\",\"M\"])): lambda J, M: pdf_jm([J, M]),\n",
    "            tuple(sorted([\"S\"])): lambda S: pdf_s([S]),\n",
    "            tuple(sorted([\"P\"])): lambda P: pdf_p([P]),\n",
    "            tuple(sorted([\"A\"])): lambda A: pdf_a([A])}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[16.,  1.,  0., ...,  1.,  1.,  1.],\n       [17.,  0.,  0., ...,  2.,  1.,  0.],\n       [19.,  0.,  0., ...,  1.,  1.,  1.],\n       ...,\n       [15.,  0.,  0., ...,  2.,  1.,  1.],\n       [15.,  0.,  0., ...,  2.,  1.,  1.],\n       [18.,  0.,  0., ...,  2.,  1.,  0.]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ajkmnps = np.concatenate((A_train, J_train, K_train, M_train, N_train, P_train,S_train),axis=1)\n",
    "\n",
    "data_ajkmnps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T14:18:10.565447Z",
     "start_time": "2024-03-05T14:18:10.508794Z"
    }
   },
   "id": "6af106b6099c5b62",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69bff60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-04T22:39:54.748599Z",
     "start_time": "2024-03-04T22:39:52.651921Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m cb_data \u001B[38;5;241m=\u001B[39m \u001B[43mcb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgeneral_causal_bootstrapping_simple\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight_func_lam\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mweight_func_lam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mdist_map\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdist_map\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                 \u001B[49m\u001B[43mintv_var_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mSS\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/causalBootstrapping.py:341\u001B[0m, in \u001B[0;36mgeneral_causal_bootstrapping_simple\u001B[0;34m(weight_func_lam, dist_map, data, intv_var_name, kernel, mode)\u001B[0m\n\u001B[1;32m    339\u001B[0m weights \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((N, \u001B[38;5;28mlen\u001B[39m(cause_unique)))\n\u001B[1;32m    340\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, y \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(cause_unique):\n\u001B[0;32m--> 341\u001B[0m     weights[:,i]\u001B[38;5;241m=\u001B[39m\u001B[43mweight_compute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight_func\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mw_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43mintv_var\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43mintv_var_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    343\u001B[0m bootstrapped_data \u001B[38;5;241m=\u001B[39m bootstrapper(data \u001B[38;5;241m=\u001B[39m data, weights \u001B[38;5;241m=\u001B[39m weights, intv_var_name_in_data \u001B[38;5;241m=\u001B[39m [intv_var_name_in_data], mode \u001B[38;5;241m=\u001B[39m mode)\n\u001B[1;32m    345\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m bootstrapped_data\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/causalBootstrapping.py:36\u001B[0m, in \u001B[0;36mweight_compute\u001B[0;34m(weight_func, data, intv_var)\u001B[0m\n\u001B[1;32m     34\u001B[0m             value_i \u001B[38;5;241m=\u001B[39m value_i\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     35\u001B[0m         kwargs[key] \u001B[38;5;241m=\u001B[39m value_i\n\u001B[0;32m---> 36\u001B[0m     weights[i] \u001B[38;5;241m=\u001B[39m \u001B[43mweight_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m weights\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/causalBootstrapping.py:59\u001B[0m, in \u001B[0;36mweight_func.<locals>.divide_functions.<locals>.division\u001B[0;34m(**kwargs)\u001B[0m\n\u001B[1;32m     57\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m {key\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_prime\u001B[39m\u001B[38;5;124m\"\u001B[39m): value \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m     58\u001B[0m param \u001B[38;5;241m=\u001B[39m {key : kwargs[key] \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m param_names}\n\u001B[0;32m---> 59\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfuncs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(w_nom) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m nom_i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;28mlen\u001B[39m(w_nom)):\n",
      "Cell \u001B[0;32mIn[20], line 15\u001B[0m, in \u001B[0;36m<lambda>\u001B[0;34m(A, J, K, M, N, P, S)\u001B[0m\n\u001B[1;32m     12\u001B[0m dist_estimator_a \u001B[38;5;241m=\u001B[39m MultivarContiDistributionEstimator(data_fit\u001B[38;5;241m=\u001B[39mdata_a, n_bins \u001B[38;5;241m=\u001B[39m n_bins_a)\n\u001B[1;32m     13\u001B[0m pdf_a, pa \u001B[38;5;241m=\u001B[39m dist_estimator_a\u001B[38;5;241m.\u001B[39mfit_kde()\n\u001B[0;32m---> 15\u001B[0m dist_map \u001B[38;5;241m=\u001B[39m {\u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28msorted\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJ\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mK\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m])): \u001B[38;5;28;01mlambda\u001B[39;00m A, J, K, M, N, P, S: \u001B[43mpdf_ajkmnps\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mJ\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mK\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mM\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mP\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mS\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m ,\n\u001B[1;32m     16\u001B[0m             \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28msorted\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mK\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mN\u001B[39m\u001B[38;5;124m\"\u001B[39m])): \u001B[38;5;28;01mlambda\u001B[39;00m K, N: pdf_kn([K, N]),\n\u001B[1;32m     17\u001B[0m             \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28msorted\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJ\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m\"\u001B[39m])): \u001B[38;5;28;01mlambda\u001B[39;00m J, M: pdf_jm([J, M]),\n\u001B[1;32m     18\u001B[0m             \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28msorted\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m])): \u001B[38;5;28;01mlambda\u001B[39;00m S: pdf_s([S]),\n\u001B[1;32m     19\u001B[0m             \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28msorted\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mP\u001B[39m\u001B[38;5;124m\"\u001B[39m])): \u001B[38;5;28;01mlambda\u001B[39;00m P: pdf_p([P]),\n\u001B[1;32m     20\u001B[0m             \u001B[38;5;28mtuple\u001B[39m(\u001B[38;5;28msorted\u001B[39m([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mA\u001B[39m\u001B[38;5;124m\"\u001B[39m])): \u001B[38;5;28;01mlambda\u001B[39;00m A: pdf_a([A])}\n",
      "File \u001B[0;32m~/Desktop/DSGP8/venv/lib/python3.11/site-packages/scipy/stats/_kde.py:257\u001B[0m, in \u001B[0;36mgaussian_kde.evaluate\u001B[0;34m(self, points)\u001B[0m\n\u001B[1;32m    237\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, points):\n\u001B[1;32m    238\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Evaluate the estimated pdf on a set of points.\u001B[39;00m\n\u001B[1;32m    239\u001B[0m \n\u001B[1;32m    240\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    255\u001B[0m \n\u001B[1;32m    256\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 257\u001B[0m     points \u001B[38;5;241m=\u001B[39m atleast_2d(\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpoints\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    259\u001B[0m     d, m \u001B[38;5;241m=\u001B[39m points\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m d \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md:\n",
      "\u001B[0;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "cb_data = cb.general_causal_bootstrapping_simple(weight_func_lam = weight_func_lam, \n",
    "                                                 dist_map = dist_map, data = data, \n",
    "                                                 intv_var_name = \"S\", kernel = SS)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "48edc48c91f20e91"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
