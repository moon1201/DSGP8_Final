{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52be4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('student.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0a696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sex'] = df['sex'].replace({'F': 0, 'M': 1})\n",
    "df['Pstatus'] = df['Pstatus'].replace({'A': 0, 'T': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550f5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns_D = ['sex', 'age', 'Pstatus', 'famrel', 'Medu', 'Mjob', 'Fedu', 'Fjob', 'goout', 'health', 'Dalc']\n",
    "# selected_columns_W = ['sex', 'age', 'Pstatus', 'famrel', 'Medu', 'Mjob', 'Fedu', 'Fjob', 'Walc']\n",
    "\n",
    "df_D = df[selected_columns_D].copy()\n",
    "# df_W = df[selected_columns_W].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0df3071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex         int64\n",
      "age         int64\n",
      "Pstatus     int64\n",
      "famrel      int64\n",
      "Medu        int64\n",
      "Mjob       object\n",
      "Fedu        int64\n",
      "Fjob       object\n",
      "goout       int64\n",
      "health      int64\n",
      "Dalc       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_D['Dalc'] = df_D['Dalc'].astype(str)\n",
    "print(df_D.dtypes)\n",
    "df_D.to_csv('df_D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1094f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "X = df_D[['sex', 'age', 'Pstatus', 'famrel', 'Medu', 'Mjob', 'Fedu', 'Fjob', 'goout', 'health']]\n",
    "X = pd.get_dummies(X, columns=['Mjob', 'Fjob'])\n",
    "\n",
    "y = df_D['Dalc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f666eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9952c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "\n",
    "dataset = {\n",
    "    'data': X,\n",
    "    'target': y,\n",
    "    'DESCR': 'Student alcohol consumption during weekday',\n",
    "    'feature_names': ['sex', 'age', 'Pstatus', 'famrel', 'Medu', 'Fedu', 'goout', 'health',\n",
    "                      'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher',\n",
    "                      'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher'],\n",
    "    'target_names': ['very low', 'low', 'moderate', 'high', 'very high'],\n",
    "}\n",
    "\n",
    "bunch = Bunch(**dataset)\n",
    "\n",
    "X = bunch.data\n",
    "y = bunch.target\n",
    "\n",
    "feature_names = bunch.feature_names\n",
    "class_names = bunch.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = { \n",
    "#     'n_estimators': [5, 10, 15, 20, 25, 50, 100, 150], \n",
    "#     'max_features': ['sqrt', 'log2', None], \n",
    "#     'max_depth': [2,3,4,5,6,7,8,9], \n",
    "# #     'max_leaf_nodes': [3, 6, 9], \n",
    "# } \n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "#                            param_grid=param_grid) \n",
    "# grid_search.fit(X_train, y_train) \n",
    "# print(grid_search.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e853cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# random_search = RandomizedSearchCV(RandomForestClassifier(), \n",
    "#                                    param_grid) \n",
    "# random_search.fit(X_train, y_train) \n",
    "# print(random_search.best_estimator_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe74f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8325358851674641\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=9, n_estimators=50, class_weight='balanced', random_state=30)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12ef8813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8086455660108355\n",
      "Recall: 0.6758933119860273\n",
      "F1 Score: 0.7275856219252446\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26a0258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[144   5   1   0   1]\n",
      " [ 20  18   1   0   0]\n",
      " [  2   0   5   0   0]\n",
      " [  1   0   0   3   0]\n",
      " [  0   4   0   0   4]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fefa5adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score     support\n",
      "very low       0.862275  0.953642  0.905660  151.000000\n",
      "low            0.666667  0.461538  0.545455   39.000000\n",
      "moderate       0.714286  0.714286  0.714286    7.000000\n",
      "high           1.000000  0.750000  0.857143    4.000000\n",
      "very high      0.800000  0.500000  0.615385    8.000000\n",
      "accuracy       0.832536  0.832536  0.832536    0.832536\n",
      "macro avg      0.808646  0.675893  0.727586  209.000000\n",
      "weighted avg   0.821070  0.832536  0.819996  209.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
    "\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce96bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '5', '1', '2', '2', '1', '2', '1', '1', '1', '1', '1', '1', '2',\n",
       "       '3', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '2',\n",
       "       '5', '1', '2', '1', '2', '1', '1', '2', '1', '1', '1', '1', '4',\n",
       "       '1', '1', '2', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1',\n",
       "       '2', '1', '1', '2', '1', '1', '3', '1', '3', '1', '2', '4', '2',\n",
       "       '1', '1', '1', '2', '1', '3', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '2', '2', '5', '1', '1', '1', '1', '2', '1', '2', '2', '5',\n",
       "       '1', '1', '1', '5', '2', '1', '1', '1', '1', '5', '1', '1', '3',\n",
       "       '2', '2', '1', '3', '1', '1', '5', '1', '1', '3', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1',\n",
       "       '1', '2', '1', '4', '1', '1', '2', '1', '2', '1', '2', '1', '1',\n",
       "       '1', '1', '1', '2', '1', '1', '1', '4', '2', '1', '1', '1', '2',\n",
       "       '1'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "889d18d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'y_test': np.array(y_test)})\n",
    "\n",
    "# df.to_csv('y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1104fc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '2', '1', '1', '1', '1', '1', '5', '1', '1', '1', '1', '1',\n",
       "       '5', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '3', '1', '1', '1', '2', '2', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '2', '1', '1', '1', '2', '1', '1', '2',\n",
       "       '1', '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '2',\n",
       "       '2', '1', '2', '1', '2', '1', '1', '1', '1', '1', '2', '1', '4',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '3', '1', '1', '1', '1', '1', '3', '1', '1', '1', '2', '4', '2',\n",
       "       '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1', '2', '2', '2', '1', '1', '1', '1', '1', '1', '1', '1', '2',\n",
       "       '1', '1', '1', '2', '2', '1', '1', '1', '1', '5', '1', '1', '3',\n",
       "       '1', '2', '1', '3', '1', '1', '5', '1', '1', '3', '1', '1', '1',\n",
       "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '3', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '1', '1',\n",
       "       '1', '1', '1', '4', '1', '1', '2', '1', '2', '1', '1', '1', '1',\n",
       "       '1', '1', '1', '2', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
       "       '1'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3faa109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'y_pred': y_pred})\n",
    "\n",
    "# df.to_csv('y_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e79b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac1ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_to_plot = 2  \n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "plt.rcParams['lines.linewidth'] = 0.3\n",
    "plot_tree(clf.estimators_[tree_to_plot], feature_names=feature_names, filled=True, class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e4a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = bunch.data.shape[1]\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
    "    plt.yticks(np.arange(n_features), bunch.feature_names)\n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "plot_feature_importances(clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403cf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import mglearn\n",
    "# fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "# for i, (ax, tree) in enumerate(zip(axes.ravel(), clf.estimators_)):\n",
    "#     ax.set_title(\"tree {}\".format(i))\n",
    "#     mglearn.plots.plot_tree_partition(X_train, y_train, tree, ax=ax)\n",
    "\n",
    "# mglearn.plots.plot_2d_separator(clf, X_train, fill=True, ax=axes[-1, -1], alpha=.4)\n",
    "# axes[-1, -1].set_title(\"Random Forest\")\n",
    "# mglearn.discrete_scatter(X_train[:, 0], X_train[:, 1], y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(X_train))\n",
    "# print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a62758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
